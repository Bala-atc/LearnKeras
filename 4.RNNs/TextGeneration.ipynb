{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TextGeneration.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2cwRRChZarLB","colab_type":"text"},"source":["**You know the deal by now, let's get started by importing our dependencies**"]},{"cell_type":"code","metadata":{"id":"tcnPK4QJX4h9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"54212a15-93d5-4a76-839e-89b5366fe0ab","executionInfo":{"status":"ok","timestamp":1563307897740,"user_tz":240,"elapsed":2229,"user":{"displayName":"Adam Eubanks","photoUrl":"https://lh3.googleusercontent.com/-3ErEfX8LneA/AAAAAAAAAAI/AAAAAAAAJXQ/UgP90W3bjV0/s64/photo.jpg","userId":"14853192264485050012"}}},"source":["import keras\n","import numpy as np\n","import random"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Gh_SPAjraxcI","colab_type":"text"},"source":["**Next, we need to load the data. It can be any text file. I decided on a text file of the writings of Neitzche because it didn't need any preprocessing and uses the io library.**"]},{"cell_type":"code","metadata":{"id":"_h6S2_fq_841","colab_type":"code","outputId":"8757fe05-ea44-45c0-b52e-4531f48f3fe5","executionInfo":{"status":"ok","timestamp":1563307899986,"user_tz":240,"elapsed":1006,"user":{"displayName":"Adam Eubanks","photoUrl":"https://lh3.googleusercontent.com/-3ErEfX8LneA/AAAAAAAAAAI/AAAAAAAAJXQ/UgP90W3bjV0/s64/photo.jpg","userId":"14853192264485050012"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["import io\n","path = keras.utils.data_utils.get_file(\n","    'nietzsche.txt',\n","    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n","with io.open(path, encoding='utf-8') as f:\n","    text = f.read().lower()\n","print(len(text))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n","606208/600901 [==============================] - 0s 1us/step\n","600893\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5hQMO99EXyE3","colab_type":"text"},"source":["**This code will help later when we need to predict which char comes next in a sequence of text.**"]},{"cell_type":"code","metadata":{"id":"kBvmmNxKAQNp","colab_type":"code","outputId":"e3cc8422-6473-43a8-da96-5c069ac55162","executionInfo":{"status":"ok","timestamp":1563307902065,"user_tz":240,"elapsed":362,"user":{"displayName":"Adam Eubanks","photoUrl":"https://lh3.googleusercontent.com/-3ErEfX8LneA/AAAAAAAAAAI/AAAAAAAAJXQ/UgP90W3bjV0/s64/photo.jpg","userId":"14853192264485050012"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["chars = sorted(list(set(text)))\n","print('total chars:', len(chars))\n","char_indices = dict((c, i) for i, c in enumerate(chars))\n","indices_char = dict((i, c) for i, c in enumerate(chars))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["total chars: 57\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hnNEqrVYYVQ3","colab_type":"text"},"source":["**Now we create multidimensional arrays out of the text data that we inputed. This will be used for training and make everything more coherent. The number 40 represents the max number of letters a word can have.**"]},{"cell_type":"code","metadata":{"id":"Qg92P-wHAU3N","colab_type":"code","colab":{}},"source":["sentences = []\n","next_chars = []\n","for i in range(0, len(text) - 40, 3):\n","    sentences.append(text[i: i + 40])\n","    next_chars.append(text[i + 40])\n","\n","x = np.zeros((len(sentences), 40, len(chars)), dtype=np.bool)\n","y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        x[i, t, char_indices[char]] = 1\n","    y[i, char_indices[next_chars[i]]] = 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KJiXtDEZbLi_","colab_type":"text"},"source":["**Now, let's build the model with an LSTM layer**\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"T_zsIphcAa6t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"65f9fcf8-fccb-40f4-b992-fe8c58ea35bc","executionInfo":{"status":"ok","timestamp":1563307911373,"user_tz":240,"elapsed":586,"user":{"displayName":"Adam Eubanks","photoUrl":"https://lh3.googleusercontent.com/-3ErEfX8LneA/AAAAAAAAAAI/AAAAAAAAJXQ/UgP90W3bjV0/s64/photo.jpg","userId":"14853192264485050012"}}},"source":["model = keras.models.Sequential()\n","model.add(keras.layers.LSTM(128, input_shape=(40, len(chars))))\n","model.add(keras.layers.Dense(len(chars), activation='softmax'))\n","\n","optimizer = keras.optimizers.RMSprop(lr=0.01)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0716 20:11:50.872472 140344017909632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0716 20:11:50.923416 140344017909632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0716 20:11:50.933299 140344017909632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0716 20:11:51.279042 140344017909632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0716 20:11:51.291764 140344017909632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"pgt2LBkDZhzc","colab_type":"text"},"source":["**This function will compare the sample predictions with the original text.**"]},{"cell_type":"code","metadata":{"id":"HF9o0C9DAhVH","colab_type":"code","colab":{}},"source":["def sample(preds, temperature=1.0):\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1o4MuCL6bWGj","colab_type":"text"},"source":["**Next, train the model. It is recommended that at least 20 epochs are given to the model, however this can take quite a while so be prepared. The output text should be around 400 characters.**"]},{"cell_type":"code","metadata":{"id":"g2F0MBGAA32f","colab_type":"code","outputId":"4f17b092-81df-402d-e169-ccddf620ec00","executionInfo":{"status":"ok","timestamp":1563308380476,"user_tz":240,"elapsed":464590,"user":{"displayName":"Adam Eubanks","photoUrl":"https://lh3.googleusercontent.com/-3ErEfX8LneA/AAAAAAAAAAI/AAAAAAAAJXQ/UgP90W3bjV0/s64/photo.jpg","userId":"14853192264485050012"}},"colab":{"base_uri":"https://localhost:8080/","height":163}},"source":["model.fit(x, y, batch_size=18, epochs=1)\n","start_index = random.randint(0, len(text) - 40 - 1)\n","for diversity in [0.2, 0.5, 1.0, 1.2]:\n","    generated = ''\n","    sentence = text[start_index: start_index + 40]\n","    generated += sentence\n","\n","    for i in range(400):\n","        x_pred = np.zeros((1, 40, len(chars)))\n","        for t, char in enumerate(sentence):\n","            x_pred[0, t, char_indices[char]] = 1.\n","\n","        preds = model.predict(x_pred, verbose=0)[0]\n","        next_index = sample(preds, diversity)\n","        next_char = indices_char[next_index]\n","\n","        generated += next_char\n","        sentence = sentence[1:] + next_char\n","with open('example.txt', 'w') as f:\n","    f.write(generated)\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["W0716 20:11:56.292767 140344017909632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0716 20:11:56.950916 140344017909632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","200285/200285 [==============================] - 458s 2ms/step - loss: 1.9765\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-HzoamuVbY4R","colab_type":"text"},"source":["**Finally, save the sample text to your computer (optional)**"]},{"cell_type":"code","metadata":{"id":"Ya8tF_K8B09t","colab_type":"code","colab":{}},"source":["from google.colab import files\n","files.download('example.txt')"],"execution_count":0,"outputs":[]}]}